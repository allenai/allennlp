allennlp.data.tokenizers
================================

.. automodule:: allennlp.data.tokenizers
   :members:
   :undoc-members:
   :show-inheritance:

* :ref:`Tokenizer<tokenizer>`
* :ref:`SpacyTokenizer<spacy-tokenizer>`
* :ref:`CharacterTokenizer<character-tokenizer>`
* :ref:`PretrainedTransformerTokenizer<pretrained-transformer-tokenizer>`
* :ref:`OpenAIPreTokenizer<pretrained-transformer-pre-tokenizer>`
* :ref:`BertPreTokenizer<pretrained-transformer-pre-tokenizer>`
* :ref:`LettersDigitsTokenizer<letters-digits-tokenizer>`
* :ref:`WhiteSpaceTokenizer<white-space-tokenizer>`


.. _tokenizer:
.. automodule:: allennlp.data.tokenizers.tokenizer
   :members:
   :undoc-members:
   :show-inheritance:

.. _spacy-tokenizer:
.. automodule:: allennlp.data.tokenizers.spacy_tokenizer
   :members:
   :undoc-members:
   :show-inheritance:

.. _character-tokenizer:
.. automodule:: allennlp.data.tokenizers.character_tokenizer
   :members:
   :undoc-members:
   :show-inheritance:

.. _pretrained-transformer-tokenizer:
.. automodule:: allennlp.data.tokenizers.pretrained_transformer_tokenizer
   :members:
   :undoc-members:
   :show-inheritance:

.. _pretrained-transformer-pre-tokenizer:
.. automodule:: allennlp.data.tokenizers.pretrained_transformer_pre_tokenizer
   :members:
   :undoc-members:
   :show-inheritance:

.. _letters-digits-tokenizer:
.. automodule:: allennlp.data.tokenizers.letters_digits_tokenizer
   :members:
   :undoc-members:
   :show-inheritance:

.. _white-space-tokenizer:
.. automodule:: allennlp.data.tokenizers.whitespace_tokenizer
   :members:
   :undoc-members:
   :show-inheritance:

.. automodule:: allennlp.data.tokenizers.token
   :members:
   :undoc-members:
   :show-inheritance:

.. _sentence-splitter:
.. automodule:: allennlp.data.tokenizers.sentence_splitter
   :members:
   :undoc-members:
   :show-inheritance: