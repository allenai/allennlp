from typing import Sequence, Optional, overload, Union, Tuple, TypeVar, Any, IO
from types import ModuleType

from .tensor import _TensorBase, Tensor, LongTensor, ByteTensor, IntTensor, FloatTensor
from .autograd.variable import Variable
from .storage import Storage

T = TypeVar('T', bound='_TensorBase')
TV = Union[T, Variable]

import torch.cuda
import torch.nn.functional
import torch.nn.modules
import torch.optim
import torch.optim.lr_scheduler

import numpy as np

def cat(seq: Sequence[Variable], dim: int = 0, out: Optional[Variable] = None) -> Variable: ...

def stack(seq: Sequence[Variable], dim: int = 0, out: Optional[Variable] = None) -> Variable: ...

def gather(input: Variable, dim: int, index: Variable[LongTensor], out: Optional[Variable] = None) -> Variable: ...

def arange(start: float, end: float, step: float = 1, out: Tensor=None) -> Tensor: ...

def manual_seed(seed: int) -> None: ...
def rand(sizes: Sequence[int], out: Optional[Tensor] = None) -> Tensor: ...

def from_numpy(a: np.ndarray) -> Tensor: ...

@overload
def max(tensor: T) -> float: ...
@overload
def max(tensor: Variable) -> Variable: ...
@overload
def max(tensor: T, dim: int, keepdim: Optional[bool] = None) -> Tuple[T, T]: ...
@overload
def max(tensor: Variable, dim: int, keepdim: Optional[bool] = None) -> Tuple[Variable, Variable]: ...
def max(tensor: TV, dim: Optional[int] = None, keepdim: Optional[bool] = None) -> Union[float, Variable, Tuple[TV, TV]]: ...

@overload
def sum(tensor: T) -> float: ...
@overload
def sum(tensor: Variable) -> Variable: ...
def sum(tensor: TV,
        dim: Optional[int] = None,
        keepdim: Optional[bool] = False,
        out: Optional[TV] = None) -> Any: ...  # not sure why Any is required here

def matmul(tensor1: Variable, tensor2: Variable, out: Optional[Variable] = None) -> Variable: ...

def abs(tensor: TV) -> TV: ...

def ones(*size: int, out: Optional[T] = None) -> T: ...

def exp(tensor: TV, out: Optional[TV] = None) -> TV: ...
def pow(input: TV, exponent: Union[float, TV], out: Optional[TV] = None) -> TV: ...
def sigmoid(input: TV, out: Optional[TV] = None) -> TV: ...
def tanh(input: TV, out: Optional[TV] = None) -> TV: ...

def transpose(input: TV, dim1: int, dim2: int, out: Optional[TV] = None) -> TV: ...

# TODO(joelgrus): these are bad type signatures
def load(f: Union[str, IO], map_location: Any = None, pickle_module: Any = None) -> Any: ...
def save(obj: Any, f: Union[str, IO], pickle_module: Any = None, pickle_protocol: int = 2) -> Any: ...
