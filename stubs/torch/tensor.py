from typing import Union, Optional, TypeVar, Sequence, overload, Any, List, Tuple

import torch
from torch.autograd import Variable
import numpy as np

VarTensor = Union['_TensorBase', 'torch.autograd.Variable']

Index = Union['torch.autograd.Variable', '_TensorBase', int, slice, Sequence[Union[int, slice]]]
Value = Union[float, int, '_TensorBase']

T = TypeVar('T', bound='_TensorBase')

class _TensorBase:
    def __init__(self, *dims: int) -> None: ...

    @overload
    def size(self) -> Sequence[int]: ...
    @overload
    def size(self, dim: int) -> int: ...
    def size(self, dim: Optional[int] = None) -> Union[int, Sequence[int]]: ...

    @overload
    def sum(self) -> float: ...
    @overload
    def sum(self: T, dim: int, keepdim: bool = False, out: Optional[T] = None) -> T: ...
    def sum(self: T,
            dim: Optional[int] = None,
            keepdim: Optional[bool] = False,
            out: Optional[T] = None) -> Any: ...  # not sure why Any is required here

    def norm(self,
             p: float = 2.,
             dim: Optional[int] = None,
             keepdim: bool = False) -> float: ...

    shape: Sequence[int]

    def dim(self) -> int: ...
    def ndim(self) -> int: ...
    def numel(self) -> int: ...
    def nelement(self) -> int: ...

    def __getitem__(self: T, key: Index) -> T: ...
    def __setitem__(self: T, key: Index, value: Value) -> T: ...

    # see https://github.com/python/mypy/issues/2783#issuecomment-276596902
    def __eq__(self, other: Any) -> 'ByteTensor': ...  # type: ignore
    def __lt__(self, other: Any) -> 'ByteTensor': ...  # type: ignore
    def __le__(self, other: Any) -> 'ByteTensor': ...  # type: ignore
    def __gt__(self, other: Any) -> 'ByteTensor': ...  # type: ignore
    def __ge__(self, other: Any) -> 'ByteTensor': ...  # type: ignore
    def __ne__(self, other: Any) -> 'ByteTensor': ...  # type: ignore

    def __add__(self: T, other: Value) -> T: ...
    def __radd__(self: T, other: Value) -> T: ...
    def __iadd__(self: T, other: Value) -> T: ...

    def __sub__(self: T, other: Value) -> T: ...
    def __rsub__(self: T, other: Value) -> T: ...
    def __isub__(self: T, other: Value) -> T: ...

    def __mul__(self: T, other: Value) -> T: ...
    def __rmul__(self: T, other: Value) -> T: ...
    def __imul__(self: T, other: Value) -> T: ...
    def __matmul__(self: T, other: Value) -> T: ...

    def __truediv__(self: T, other: Value) -> T: ...
    def __rtruediv__(self: T, other: Value) -> T: ...
    def __itruediv__(self: T, other: Value) -> T: ...

    def __neg__(self: T) -> T: ...

    def numpy(self) -> np.ndarray: ...

    def cpu(self: T) -> T: ...
    def new(self: T, *args, **kwargs) -> T: ...

    def view_as(self: T, other: T) -> T: ...
    def resize_(self: T, *sizes: int) -> T: ...
    def fill_(self: T, value: float) -> T: ...
    def zero_(self: T) -> T: ...

    @overload
    def max(self: T) -> float: ...
    @overload
    def max(self: T, dim: int, keepdim: Optional[bool] = False) -> Tuple[T, T]: ...
    def max(self: T,
            dim: Optional[int] = None,
            keepdim: Optional[bool] = False) -> Union[float, Tuple[T, T]]: ...

    def backward(self,
                 gradient: Optional[VarTensor] = None,
                 retain_graph: Optional[bool] = None,
                 create_graph: Optional[bool] = None) -> None: ...

    def squeeze(self: T, dim: Optional[int] = None) -> T: ...
    def unsqueeze(self: T, dim: int) -> T: ...
    def unsqueeze_(self: T, dim: int) -> T: ...

    def view(self: T, *dims: int) -> T: ...
    def expand(self: T, *dims: int) -> T: ...
    def expand_as(self: T, other: _TensorBase) -> T: ...

    def contiguous(self: T) -> T: ...

    def normal_(self: T, mean: float = 0., std: float = 1.) -> T: ...

    def clone(self: T) -> T: ...

    def copy_(self: T, src: T, async: bool = False, broadcast: bool = True) -> T: ...

    def tolist(self) -> list: ...
    def split(self: T, split_size: int, dim: int = 0) -> Sequence[T]: ...

    def any(self) -> bool: ...
    def eq(self, other: _TensorBase) -> 'ByteTensor': ...

    def topk(self: T,
             k: int,
             dim: Optional[int] = None,
             largest: bool = True,
             sorted: bool = True,
             out: Optional[T] = None) -> Tuple[T, 'LongTensor']: ...

    def long(self) -> 'LongTensor': ...
    def float(self) -> 'FloatTensor': ...


class Tensor(_TensorBase): pass
class LongTensor(_TensorBase): pass
class IntTensor(_TensorBase): pass
class FloatTensor(_TensorBase): pass
class ByteTensor(_TensorBase): pass
