# allennlp.modules.attention.dot_product_attention

## DotProductAttention
```python
DotProductAttention(self, normalize:bool=True) -> None
```

Computes attention between a vector and a matrix using dot product.

