{
  "dataset_reader":{
    "type":"java",
    "utterance_indexers":{"tokens": {"namespace": "utterance"}},
    "type_indexers":{"tokens": {"namespace": "type"}},
    // # todo(rajas): figure out why identifier count of 1 causes a 0 grad
    // for linking params.
    "min_identifier_count": 2,
    "linking_feature_extractors": [
      "exact_token_match",
      "contains_exact_token_match",
      "substring_token_match_larger_than_three",
      "neighbor_exact_match",
      "neighbor_contains_exact_match",
      "neighbor_substring_token_match_larger_than_three",
      "is_in_prototype"
    ]
  },
  "vocabulary": {
    "min_count": {"utterance": 2, "type": 2}
  },
  "train_data_path": "/home/rajas/semparse/java-programmer/data/added-path-methodname/valid-with-edits-small.json",
//  "train_data_path": "/home/rajas/semparse/java-programmer/data/added-path-methodname/valid-with-edits-small.json",
  "validation_data_path": "/home/rajas/semparse/java-programmer/data/added-path-methodname/valid-with-edits-small.json",
  "test_data_path": "/home/rajas/semparse/java-programmer/data/added-path-methodname/valid-with-edits-small.json",

  "model": {
    "action_embedding_dim": 50,
    "num_linking_features": 7,
    "dropout": 0.5,
    "type": "java_parser",
    "utterance_embedder": {
      "tokens": {
        "type": "embedding",
        "vocab_namespace": "utterance",
        "embedding_dim": 50,
        "trainable": true
      }
    },
    "encoder": {
      "type": "lstm",
      "input_size": 50,
      "hidden_size": 25,
      "num_layers": 1,
      "bidirectional": true
    },
    "proto_encoder": {
      "type": "lstm",
      "input_size": 50,
      "hidden_size": 25,
      "num_layers": 1,
      "bidirectional": true
    },
    "prototype_feedforward": {
      "input_dim": 50,
      "num_layers": 3,
      "hidden_dims": [5, 2, 1],
      "activations": ["relu", "sigmoid", "sigmoid"],
      "dropout": [0.2, 0.0, 0.0]
    },
    "mixture_feedforward": {
      "input_dim": 50,
      "num_layers": 3,
      "hidden_dims": [5, 2, 1],
      "activations": ["relu", "sigmoid", "sigmoid"],
      "dropout": [0.2, 0.0, 0.0]
    },
    "max_decoding_steps": 150,
    "decoder_beam_search": {
      "beam_size": 3
    },
    "attention_function": {"type": "dot_product"}
  },
//  "iterator": {
//    "type": "bucket",
//    "padding_noise": 0.0,
//    "batch_size" : 4,
//    "sorting_keys": [["rules", "dimension_0"]]
//  },
  "iterator": {
    "type": "basic",
    "batch_size" : 20
  },
  "trainer": {
    "num_epochs": 2,
    "patience": 10,
    "validation_metric": "+bleu",
    "cuda_device": -1,
    "optimizer": {
      "type": "adam",
      "lr": 0.01
    }
  }
}
