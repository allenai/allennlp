{
  "dataset_reader": {
    "type": "seq2seq",
    "source_tokenizer": {
      "type": "spacy",
      "pos_tags": true,
      "parse": true,
      "ner": true
    },
    "target_tokenizer": {
      "type": "spacy"
    },
    "source_token_indexers": {
      "tokens": {
        "type": "single_id",
        "namespace": "source_tokens"
      },
      "pos_tags": {
        "type": "pos_tag",
        "namespace": "pos"
      },
      "dependency_label": {
        "type": "dependency_label",
        "namespace": "dependencies"
      },
      "ner_tags": {
        "type": "ner_tag",
        "namespace": "ner"
      }
    },
    "target_token_indexers": {
      "tokens": {
        "namespace": "target_tokens"
      }
    }
  },
  "train_data_path": "allennlp/tests/fixtures/data/seq2seq_copy.tsv",
  "validation_data_path": "allennlp/tests/fixtures/data/seq2seq_copy.tsv",
  "model": {
    "type": "composed_seq2seq",
    "source_text_embedder": {
      "token_embedders": {
        "tokens": {
          "type": "embedding",
          "vocab_namespace": "source_tokens",
          "embedding_dim": 25,
          "trainable": true
        },
        "pos_tags": {
          "type": "embedding",
          "vocab_namespace": "pos",
          "embedding_dim": 5
        },
        "ner_tags": {
          "type": "embedding",
          "vocab_namespace": "ner",
          "embedding_dim": 7
        },
        "dependency_label": {
          "type": "embedding",
          "vocab_namespace": "dependencies",
          "embedding_dim": 10
        }
      }
    },
    "encoder": {
      "type": "lstm",
      "input_size": 47,
      "hidden_size": 10,
      "num_layers": 1
    },
    "decoder": {
      "decoder_net": {
         "type": "lstm_cell",
         "decoding_dim": 10,
         "target_embedding_dim": 20,
         "attention": {
           "type": "dot_product"
         }
      },
      "max_decoding_steps": 20,
      "target_namespace": "target_tokens",
      "target_embedder": {
        "vocab_namespace": "target_tokens",
        "embedding_dim": 20
      },
      "scheduled_sampling_ratio": 0.9,
      "beam_size": 5
    }
  },
  "iterator": {
    "type": "bucket",
    "padding_noise": 0.0,
    "batch_size" : 80,
    "sorting_keys": [["source_tokens", "num_tokens"]]
  },
  "trainer": {
    "num_epochs": 2,
    "patience": 10,
    "cuda_device": -1,
    "optimizer": {
      "type": "adam",
      "lr": 0.01
    }
  }
}
